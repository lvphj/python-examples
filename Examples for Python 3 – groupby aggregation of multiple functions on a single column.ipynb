{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of aggregating multiple functions on the same columns of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phjGenerateExampleData as phjData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date             datetime64[ns]\n",
      "group                     int64\n",
      "random_normal           float64\n",
      "string1                  object\n",
      "string2                  object\n",
      "dtype: object\n",
      "This dataset consists of a series of dates, a group ID (1-5) and a random variable. The desired output is to group the data by the group ID and then calculate several statistics for each column of data. So, for example, it would be useful to calculate the mean and SD from the random variable and the earliest and latest dates for each group from the data variable.\n",
      "\n",
      "         date  group  random_normal string1 string2\n",
      "0  2016-01-01      4       4.691670       a       A\n",
      "1  2016-01-02      5       3.889511       b       B\n",
      "2  2016-01-03      5       7.188339       c       C\n",
      "3  2016-01-04      1       2.288360       d       D\n",
      "4  2016-01-05      2       4.794914       e       E\n",
      "..        ...    ...            ...     ...     ...\n",
      "26 2016-01-27      1       4.089191       a       A\n",
      "27 2016-01-28      2       4.944877       b       B\n",
      "28 2016-01-29      4       3.910727       c       C\n",
      "29 2016-01-30      1       4.665064       d       D\n",
      "30 2016-01-31      4       5.292944       e       E\n",
      "\n",
      "[31 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "phjTempDF = phjData.phjPandasDF12()\n",
    "\n",
    "print(phjTempDF.dtypes)\n",
    "\n",
    "# Could Convert date to datetime if it wasn't already in th...\n",
    "phjTempDF['date'] = pd.to_datetime(phjTempDF['date'], dayfirst = True)\n",
    "\n",
    "print('This dataset consists of a series of dates, a group ID (1-5) and a random variable. The desired output is to group the data by the group ID and then calculate several statistics for each column of data. So, for example, it would be useful to calculate the mean and SD from the random variable and the earliest and latest dates for each group from the data variable.\\n')\n",
    "\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', 6):\n",
    "    print(phjTempDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could calculate just a single parameter from each variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group  random_normal       date\n",
      "0      1       4.378687 2016-01-04\n",
      "1      2       5.594723 2016-01-05\n",
      "2      3       4.770124 2016-01-08\n",
      "3      4       4.381841 2016-01-01\n",
      "4      5       5.412843 2016-01-02\n"
     ]
    }
   ],
   "source": [
    "phjTempGroupbyDF = phjTempDF.groupby('group').agg({'date': np.min,\n",
    "                                                   'random_normal': np.mean})\n",
    "\n",
    "phjTempGroupbyDF = phjTempGroupbyDF.reset_index(drop=False)\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also concatenate strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group  random_normal                    string1                    string2  \\\n",
      "0      1       4.378687  d / n / o / q / t / a / d  D - N - O - Q - T - A - D   \n",
      "1      2       5.594723          e / f / g / r / b          E - F - G - R - B   \n",
      "2      3       4.770124      h / l / m / s / w / x      H - L - M - S - W - X   \n",
      "3      4       4.381841  a / i / u / y / z / c / e  A - I - U - Y - Z - C - E   \n",
      "4      5       5.412843      b / c / j / k / p / v      B - C - J - K - P - V   \n",
      "\n",
      "        date  \n",
      "0 2016-01-04  \n",
      "1 2016-01-05  \n",
      "2 2016-01-08  \n",
      "3 2016-01-01  \n",
      "4 2016-01-02  \n"
     ]
    }
   ],
   "source": [
    "phjTempGroupbyDF = phjTempDF.groupby('group').agg({'date': np.min,\n",
    "                                                   'random_normal': np.mean,\n",
    "                                                   'string1': lambda x: ' / '.join(x),\n",
    "                                                   'string2': lambda x: ' - '.join(x)})\n",
    "\n",
    "phjTempGroupbyDF = phjTempGroupbyDF.reset_index(drop=False)\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When there are dates within groups and we want the first or last of those dates, it's a good idea to sort_values on grouping variable and dates before doing groupby. (This was an answer to one of my StackOverflow questions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group  random_normal                    string1                    string2  \\\n",
      "0      1       4.378687  d / n / o / q / t / a / d  D - N - O - Q - T - A - D   \n",
      "1      2       5.594723          e / f / g / r / b          E - F - G - R - B   \n",
      "2      3       4.770124      h / l / m / s / w / x      H - L - M - S - W - X   \n",
      "3      4       4.381841  a / i / u / y / z / c / e  A - I - U - Y - Z - C - E   \n",
      "4      5       5.412843      b / c / j / k / p / v      B - C - J - K - P - V   \n",
      "\n",
      "        date  \n",
      "0 2016-01-04  \n",
      "1 2016-01-05  \n",
      "2 2016-01-08  \n",
      "3 2016-01-01  \n",
      "4 2016-01-02  \n"
     ]
    }
   ],
   "source": [
    "phjTempGroupbyDF = phjTempDF.sort_values(['group','date']).groupby('group').agg({'date': 'first',\n",
    "                                                                                 'random_normal': np.mean,\n",
    "                                                                                 'string1': lambda x: ' / '.join(x),\n",
    "                                                                                 'string2': lambda x: ' - '.join(x)})\n",
    "\n",
    "phjTempGroupbyDF = phjTempGroupbyDF.reset_index(drop=False)\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, may need multiple parameters to be calculated per variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group random_normal                                      \\\n",
      "                 mean       std       max      amax count   \n",
      "0     1      4.378687  1.357445  6.318777  6.318777     7   \n",
      "1     2      5.594723  1.327565  7.264559  7.264559     5   \n",
      "2     3      4.770124  1.470794  6.801844  6.801844     6   \n",
      "3     4      4.381841  0.826034  5.292944  5.292944     7   \n",
      "4     5      5.412843  1.784498  7.748272  7.748272     6   \n",
      "\n",
      "                     string1                    string2       date             \n",
      "                    <lambda>                   <lambda>      first       last  \n",
      "0  d / n / o / q / t / a / d  D - N - O - Q - T - A - D 2016-01-04 2016-01-30  \n",
      "1          e / f / g / r / b          E - F - G - R - B 2016-01-05 2016-01-28  \n",
      "2      h / l / m / s / w / x      H - L - M - S - W - X 2016-01-08 2016-01-24  \n",
      "3  a / i / u / y / z / c / e  A - I - U - Y - Z - C - E 2016-01-01 2016-01-31  \n",
      "4      b / c / j / k / p / v      B - C - J - K - P - V 2016-01-02 2016-01-22  \n",
      "\n",
      "\n",
      "In this case, a dataframe with a multiple column index is produced. In order to flatten the column index, we can use a solution posted by Anday Hayden on Stack Overflow on Jan 24 2013 at 18:37 (see http://stackoverflow.com/questions/14507794/python-pandas-how-to-flatten-a-hierarchical-index-in-columns/14508355#14508355). Namely, use:\n",
      "   df.columns = [' '.join(col).strip() for col in df.columns.values]\n"
     ]
    }
   ],
   "source": [
    "phjTempGroupbyDF = phjTempDF.groupby('group').agg({'date': [\"first\", \"last\"],\n",
    "                                                   'random_normal': [np.mean, np.std, \"max\", np.max, \"count\"],\n",
    "                                                   'string1': lambda x: ' / '.join(x),\n",
    "                                                   'string2': lambda x: ' - '.join(x)})\n",
    "\n",
    "phjTempGroupbyDF = phjTempGroupbyDF.reset_index(drop=False)\n",
    "\n",
    "print(phjTempGroupbyDF)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"In this case, a dataframe with a multiple column index is produced. In order to flatten the column index, we can use a solution posted by Anday Hayden on Stack Overflow on Jan 24 2013 at 18:37 (see http://stackoverflow.com/questions/14507794/python-pandas-how-to-flatten-a-hierarchical-index-in-columns/14508355#14508355). Namely, use:\\n   df.columns = [' '.join(col).strip() for col in df.columns.values]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group_  random_normal_mean  random_normal_std  random_normal_max  \\\n",
      "0       1            4.378687           1.357445           6.318777   \n",
      "1       2            5.594723           1.327565           7.264559   \n",
      "2       3            4.770124           1.470794           6.801844   \n",
      "3       4            4.381841           0.826034           5.292944   \n",
      "4       5            5.412843           1.784498           7.748272   \n",
      "\n",
      "   random_normal_amax  random_normal_count           string1_<lambda>  \\\n",
      "0            6.318777                    7  d / n / o / q / t / a / d   \n",
      "1            7.264559                    5          e / f / g / r / b   \n",
      "2            6.801844                    6      h / l / m / s / w / x   \n",
      "3            5.292944                    7  a / i / u / y / z / c / e   \n",
      "4            7.748272                    6      b / c / j / k / p / v   \n",
      "\n",
      "            string2_<lambda> date_first  date_last  \n",
      "0  D - N - O - Q - T - A - D 2016-01-04 2016-01-30  \n",
      "1          E - F - G - R - B 2016-01-05 2016-01-28  \n",
      "2      H - L - M - S - W - X 2016-01-08 2016-01-24  \n",
      "3  A - I - U - Y - Z - C - E 2016-01-01 2016-01-31  \n",
      "4      B - C - J - K - P - V 2016-01-02 2016-01-22  \n"
     ]
    }
   ],
   "source": [
    "phjTempGroupbyDF.columns = ['_'.join(col).strip() for col in phjTempGroupbyDF.columns.values]\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But we may need to rename some columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group      mean        sd       max      max2  count  \\\n",
      "0      1  4.378687  1.357445  6.318777  6.318777      7   \n",
      "1      2  5.594723  1.327565  7.264559  7.264559      5   \n",
      "2      3  4.770124  1.470794  6.801844  6.801844      6   \n",
      "3      4  4.381841  0.826034  5.292944  5.292944      7   \n",
      "4      5  5.412843  1.784498  7.748272  7.748272      6   \n",
      "\n",
      "              string1_concat             string2_concat earliest_date  \\\n",
      "0  d / n / o / q / t / a / d  D - N - O - Q - T - A - D    2016-01-04   \n",
      "1          e / f / g / r / b          E - F - G - R - B    2016-01-05   \n",
      "2      h / l / m / s / w / x      H - L - M - S - W - X    2016-01-08   \n",
      "3  a / i / u / y / z / c / e  A - I - U - Y - Z - C - E    2016-01-01   \n",
      "4      b / c / j / k / p / v      B - C - J - K - P - V    2016-01-02   \n",
      "\n",
      "  latest_date  \n",
      "0  2016-01-30  \n",
      "1  2016-01-28  \n",
      "2  2016-01-24  \n",
      "3  2016-01-31  \n",
      "4  2016-01-22  \n"
     ]
    }
   ],
   "source": [
    "phjTempGroupbyDF = phjTempGroupbyDF.rename(columns = {'group_': 'group',\n",
    "                                                     'date_first': 'earliest_date',\n",
    "                                                     'date_last': 'latest_date',\n",
    "                                                     'random_normal_mean': 'mean',\n",
    "                                                     'random_normal_std': 'sd',\n",
    "                                                     'random_normal_max': 'max',\n",
    "                                                     'random_normal_min': 'min',\n",
    "                                                     'random_normal_amax': 'max2',\n",
    "                                                     'random_normal_count': 'count',\n",
    "                                                     'string1_<lambda>': 'string1_concat',\n",
    "                                                     'string2_<lambda>': 'string2_concat'})\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can this be done with an ordered dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('date', ['first', 'last']), ('random_normal', [<function mean at 0x1042b9950>, <function std at 0x1042b99d8>, 'max', <function amax at 0x1042b9400>, 'count']), ('string1', <function <lambda> at 0x105d989d8>), ('string2', <function <lambda> at 0x105d98f28>)])\n",
      "\n",
      "\n",
      "  group       date            random_normal                                \\\n",
      "             first       last          mean       std       max      amax   \n",
      "0     1 2016-01-04 2016-01-30      4.378687  1.357445  6.318777  6.318777   \n",
      "1     2 2016-01-05 2016-01-28      5.594723  1.327565  7.264559  7.264559   \n",
      "2     3 2016-01-08 2016-01-24      4.770124  1.470794  6.801844  6.801844   \n",
      "3     4 2016-01-01 2016-01-31      4.381841  0.826034  5.292944  5.292944   \n",
      "4     5 2016-01-02 2016-01-22      5.412843  1.784498  7.748272  7.748272   \n",
      "\n",
      "                           string1                    string2  \n",
      "  count                   <lambda>                   <lambda>  \n",
      "0     7  d / n / o / q / t / a / d  D / N / O / Q / T / A / D  \n",
      "1     5          e / f / g / r / b          E / F / G / R / B  \n",
      "2     6      h / l / m / s / w / x      H / L / M / S / W / X  \n",
      "3     7  a / i / u / y / z / c / e  A / I / U / Y / Z / C / E  \n",
      "4     6      b / c / j / k / p / v      B / C / J / K / P / V  \n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# To convert the database to one with no repeated measures, we\n",
    "# use groupby to group by a variable and then use agg() to aggregate on the\n",
    "# variables we want to keep.\n",
    "# So, we could create a dict of variables and methods that we want to keep. However,\n",
    "# Pyton dicts do not keep a track of the order. As a result, the order of variables\n",
    "# in the final dataframe would be completely different from the original. We could overcome\n",
    "# this using df = df['a','b','c'] to rearrange the columns but this would mean\n",
    "# creating a separate list of variable names.\n",
    "#\n",
    "# So instead, we can use an OrderedDict. To do this, we need to import collections.\n",
    "# Then create an ordered dict as follows and pass it to the agg() function as shown.\n",
    "\n",
    "phjAggOrderedDict = collections.OrderedDict()\n",
    "phjAggOrderedDict['date'] = [\"first\",\"last\"]\n",
    "phjAggOrderedDict['random_normal'] = [np.mean, np.std, \"max\", np.max, \"count\"]\n",
    "phjAggOrderedDict['string1'] = lambda x: ' / '.join(x)\n",
    "phjAggOrderedDict['string2'] = lambda x: ' / '.join(x)\n",
    "\n",
    "print(phjAggOrderedDict)\n",
    "\n",
    "# The following command initially sorts the dataframe by animalID and consultDate\n",
    "# to ensure that all consultations for each animal are sorted by date. Then the\n",
    "# dataframe is grouped by animalID and the various columns are aggregated as\n",
    "# defined in the ordered dictionary.\n",
    "# As of Pandas 0.17.0, sort() has been deprecated; use sort_values() instead.\n",
    "phjTempGroupbyDF = phjTempDF.sort_values(['date']).groupby('group').agg(phjAggOrderedDict).reset_index()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But what happens if there is a missing value (either NaN or None)? All hell breaks loose, that's what!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  group  random_normal string1 string2\n",
      "0  2016-01-01      4       4.691670       a       A\n",
      "1  2016-01-02      5       3.889511    None       B\n",
      "2  2016-01-03      5       7.188339       c       C\n",
      "3  2016-01-04      1       2.288360       d       D\n",
      "4  2016-01-05      2       4.794914       e       E\n",
      "5  2016-01-06      2       6.744620       f       F\n",
      "6  2016-01-07      2       7.264559       g       G\n",
      "7  2016-01-08      3       2.892246       h       H\n",
      "8  2016-01-09      4       2.862623       i       I\n",
      "9  2016-01-10      5       7.748272       j       J\n",
      "10 2016-01-11      5       3.193178       k       K\n",
      "11 2016-01-12      3       3.703031       l       L\n",
      "12 2016-01-13      3       5.616434       m     NaN\n",
      "13 2016-01-14      1       6.318777       n       N\n",
      "14 2016-01-15      1       5.552102       o       O\n",
      "15 2016-01-16      5       5.243227       p       P\n",
      "16 2016-01-17      1       3.213087       q       Q\n",
      "17 2016-01-18      2       4.224647       r       R\n",
      "18 2016-01-19      3       6.801844       s       S\n",
      "19 2016-01-20      1       4.524228       t       T\n",
      "20 2016-01-21      4       4.098566       u       U\n",
      "21 2016-01-22      5       5.214533       v       V\n",
      "22 2016-01-23      3       3.995913       w       W\n",
      "23 2016-01-24      3       5.611275       x       X\n",
      "24 2016-01-25      4       4.950651       y       Y\n",
      "25 2016-01-26      4       4.865709       z       Z\n",
      "26 2016-01-27      1       4.089191       a       A\n",
      "27 2016-01-28      2       4.944877       b       B\n",
      "28 2016-01-29      4       3.910727       c       C\n",
      "29 2016-01-30      1       4.665064       d       D\n",
      "30 2016-01-31      4       5.292944       e       E\n"
     ]
    }
   ],
   "source": [
    "phjTempDF.loc[phjTempDF['date']=='2016-01-02','string1']=None\n",
    "phjTempDF.loc[phjTempDF['date']=='2016-01-13','string2']=np.nan\n",
    "print(phjTempDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2339\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2341\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    716\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 717\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fca526e0d94c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random_normal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'string1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' - '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'string2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' / '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fca526e0d94c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'string2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' / '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mphjTempGroupbyDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphjTempDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphjTempGroupbyDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_agg_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iterate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2851\u001b[0m                     colg = SeriesGroupBy(obj[col], selection=col,\n\u001b[1;32m   2852\u001b[0m                                          grouper=self.grouper)\n\u001b[0;32m-> 2853\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_how\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2854\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__iter__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_multiple_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m             \u001b[0mcyfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_cython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   2377\u001b[0m                                          'found multiple named %s' % name)\n\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_named\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philjones/Documents/python_projects/python34_example_environment_2015-10-30/env3/lib/python3.4/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_aggregate_named\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2427\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m             \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2429\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must produce aggregated value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fca526e0d94c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"last\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random_normal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'string1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' - '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mphjAggOrderedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'string2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' / '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "phjAggOrderedDict = collections.OrderedDict()\n",
    "phjAggOrderedDict['date'] = [\"first\",\"last\"]\n",
    "phjAggOrderedDict['random_normal'] = [np.mean, np.std, \"max\", np.max, \"count\"]\n",
    "phjAggOrderedDict['string1'] = lambda x: ' - '.join(x)\n",
    "phjAggOrderedDict['string2'] = lambda x: ' / '.join(x)\n",
    "\n",
    "phjTempGroupbyDF = phjTempDF.sort_values(['date']).groupby('group').agg(phjAggOrderedDict).reset_index()\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above errors indicate that the presence of NaN or None values causes the join to fail. Instead, converting the missing values to something else before running join avoids this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group       date            random_normal                                \\\n",
      "             first       last          mean       std       max      amax   \n",
      "0     1 2016-01-04 2016-01-30      4.378687  1.357445  6.318777  6.318777   \n",
      "1     2 2016-01-05 2016-01-28      5.594723  1.327565  7.264559  7.264559   \n",
      "2     3 2016-01-08 2016-01-24      4.770124  1.470794  6.801844  6.801844   \n",
      "3     4 2016-01-01 2016-01-31      4.381841  0.826034  5.292944  5.292944   \n",
      "4     5 2016-01-02 2016-01-22      5.412843  1.784498  7.748272  7.748272   \n",
      "\n",
      "                           string1                    string2  \n",
      "  count                   <lambda>                   <lambda>  \n",
      "0     7  d - n - o - q - t - a - d  D / N / O / Q / T / A / D  \n",
      "1     5          e - f - g - r - b          E / F / G / R / B  \n",
      "2     6      h - l - m - s - w - x  H / L / EMPTY / S / W / X  \n",
      "3     7  a - i - u - y - z - c - e  A / I / U / Y / Z / C / E  \n",
      "4     6  EMPTY - c - j - k - p - v      B / C / J / K / P / V  \n"
     ]
    }
   ],
   "source": [
    "phjAggOrderedDict = collections.OrderedDict()\n",
    "phjAggOrderedDict['date'] = [\"first\",\"last\"]\n",
    "phjAggOrderedDict['random_normal'] = [np.mean, np.std, \"max\", np.max, \"count\"]\n",
    "phjAggOrderedDict['string1'] = lambda x: ' - '.join(x.fillna('EMPTY'))\n",
    "phjAggOrderedDict['string2'] = lambda x: ' / '.join(x.fillna('EMPTY'))\n",
    "\n",
    "phjTempGroupbyDF = phjTempDF.sort_values(['date']).groupby('group').agg(phjAggOrderedDict).reset_index()\n",
    "\n",
    "print(phjTempGroupbyDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
